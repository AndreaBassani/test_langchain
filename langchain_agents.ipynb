{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1571b632",
      "metadata": {
        "id": "1571b632"
      },
      "source": [
        "# Agents 🤖\n",
        "\n",
        "Agents are like \"tools\" for LLMs. They allow a LLM to access Google search, perform complex calculations with Python, and even make SQL queries.\n",
        "\n",
        "In this notebook we'll explore agents and how to use them in LangChain.\n",
        "\n",
        "We'll start by installing the prerequisite libraries that we'll be using in this example."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wPdWz1IdxyBR",
      "metadata": {
        "id": "wPdWz1IdxyBR"
      },
      "source": [
        "To run this notebook, we will need to use an OpenAI LLM. Here we will setup the LLM we will use for the whole notebook, just input your openai api key when prompted. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9765f641",
      "metadata": {},
      "source": [
        "## What is an agent?\n",
        "**Definition**: The key behind agents is giving LLM's the possibility of using tools in their workflow. This is where langchain departs from the popular chatgpt implementation and we can start to get a glimpse of what it offers us as builders. Until now, we covered several building blocks in isolation. Let's see them come to life.\n",
        "\n",
        "The official definition of agents is the following:\n",
        "\n",
        "\n",
        "> Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\n",
        "In this edition we will cover what we may call 'generic' agents which really able to perform many meta tasks. There are other more specific agents that are tuned for different tasks (called 'agent-toolkits'), but we will cover those in a future edition.\n",
        "\n",
        "In this section we will review several agents and see how they 'think' and what they can do.\n",
        "Using one of langchain's pre-built agents involves three variables: \n",
        "* defining the tools\n",
        "* defining the llm\n",
        "* defining the agent type\n",
        "\n",
        "This is all really easy to do in langchain, as we will see in the following examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c02c4fa2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c02c4fa2",
        "outputId": "f5843a3b-2e86-4616-88a4-e85c828fb9ba"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "73bfcbb6",
      "metadata": {
        "id": "73bfcbb6"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.agents import Tool\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "# initialise the llm model\n",
        "llm = OpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "72d8968f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenAI(cache=None, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x0000027E7FE10CD0>, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "309g_2pqxzzB",
      "metadata": {
        "id": "309g_2pqxzzB"
      },
      "source": [
        "As we did before, we will be counting our tokens in each call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "DsC3szr6yP3L",
      "metadata": {
        "id": "DsC3szr6yP3L"
      },
      "outputs": [],
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "# define a function that return the agent answer alongside the cost in token of the query\n",
        "def output_and_tokens(agent, query):\n",
        "    with get_openai_callback() as cb:\n",
        "        result = agent(query)\n",
        "        print(f'Spent a total of {cb.total_tokens} tokens or ${cb.total_tokens/1000*0.002}')\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd60a97c",
      "metadata": {
        "id": "bd60a97c"
      },
      "source": [
        "With all of that set up, let's jump into **Agents**."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9960a9f3",
      "metadata": {},
      "source": [
        "### Agent type #1: React Docstore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ef60be",
      "metadata": {},
      "source": [
        "This type of agent is similar to the ones we have seen so far but it includes the interaction with a docstore. It will have two and only two tools at its disposal: 'Search' and 'Lookup'."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3448130d",
      "metadata": {},
      "source": [
        "With 'Search' it will bring up a relevant article and with 'Lookup' the agent will find the right piece of information in the article. This is probably easiest to see in an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f621cf35",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain import Wikipedia\n",
        "from langchain.agents.react.base import DocstoreExplorer\n",
        "\n",
        "docstore=DocstoreExplorer(Wikipedia())\n",
        "# create a collection of tools \n",
        "# the tool is a function that the agent can use when neccesary to complite designed tasks\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        # tool to search in the page \n",
        "        func=docstore.search,\n",
        "        # tells the agent when to use the tool\n",
        "        description='search wikipedia'\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Lookup\",\n",
        "        # tool to lookup for specific terms\n",
        "        func=docstore.lookup,\n",
        "        # tells the agent when to use the tool\n",
        "        description='lookup a term in wikipedia'\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "71a99a60",
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialise the react-docstore\n",
        "docstore_agent = initialize_agent(\n",
        "    tools, \n",
        "    llm, \n",
        "    # agent that is used to interact with a document store\n",
        "    agent=\"react-docstore\", \n",
        "    verbose=True,\n",
        "    # how many iteration should the agent go through to find the answer\n",
        "    max_iterations=3\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "183d08e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search Elizabeth Alexandra Mary, find where she died.\n",
            "Action: Search[Elizabeth Alexandra Mary]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mElizabeth II (Elizabeth Alexandra Mary; 21 April 1926 – 8 September 2022) was Queen of the United Kingdom and other Commonwealth realms from 6 February 1952 until her death in 2022. She was queen regnant of 32 sovereign states during her lifetime and was head of state of 15 realms at the time of her death. Her reign of 70 years and 214 days was the longest of any British monarch and the longest verified reign of any female head of state in history.\n",
            "Elizabeth was born in Mayfair, London, as the first child of the Duke and Duchess of York (later King George VI and Queen Elizabeth The Queen Mother). Her father acceded to the throne in 1936 upon the abdication of his brother Edward VIII, making the ten-year-old Princess Elizabeth the heir presumptive. She was educated privately at home and began to undertake public duties during the Second World War, serving in the Auxiliary Territorial Service. In November 1947, she married Philip Mountbatten, a former prince of Greece and Denmark, and their marriage lasted 73 years until his death in 2021. They had four children: Charles, Anne, Andrew, and Edward.\n",
            "When her father died in February 1952, Elizabeth—then 25 years old—became queen of seven independent Commonwealth countries: the United Kingdom, Canada, Australia, New Zealand, South Africa, Pakistan, and Ceylon (known today as Sri Lanka), as well as head of the Commonwealth. Elizabeth reigned as a constitutional monarch through major political changes such as the Troubles in Northern Ireland, devolution in the United Kingdom, the decolonisation of Africa, and the United Kingdom's accession to the European Communities and withdrawal from the European Union. The number of her realms varied over time as territories gained independence and some realms became republics. As queen, Elizabeth was served by more than 170 prime ministers across her realms. Her many historic visits and meetings included state visits to China in 1986, to Russia in 1994, and to the Republic of Ireland in 2011, and meetings with five popes.\n",
            "Significant events included Elizabeth's coronation in 1953 and the celebrations of her Silver, Golden, Diamond, and Platinum jubilees in 1977, 2002, 2012, and 2022, respectively. Although she faced occasional republican sentiment and media criticism of her family—particularly after the breakdowns of her children's marriages, her annus horribilis in 1992, and the death in 1997 of her former daughter-in-law Diana—support for the monarchy in the United Kingdom remained consistently high throughout her lifetime, as did her personal popularity. Elizabeth died aged 96 at Balmoral Castle, Aberdeenshire, in September 2022 and was succeeded by her eldest son, Charles III.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Elizabeth II died at Balmoral Castle, Aberdeenshire in September 2022. So the answer is Balmoral Castle, Aberdeenshire.\n",
            "Action: Finish[Balmoral Castle, Aberdeenshire]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 3583 tokens or $0.0071660000000000005\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Where Elizabeth Alexandra Mary died?',\n",
              " 'output': 'Balmoral Castle, Aberdeenshire'}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test with a question that is after cutoff date\n",
        "output_and_tokens(docstore_agent, \"Where Elizabeth Alexandra Mary died?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2edefbe9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\nElizabeth Alexandra Mary, Queen Elizabeth II, is still alive.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# answer from the llm models\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=OPENAI_API_KEY)\n",
        "llm(\"Where Elizabeth Alexandra Mary died?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "9382aa82",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search Archimedes and find his last words.\n",
            "Action: Search[Archimedes]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mArchimedes of Syracuse (; c. 287 – c. 212 BC) was a Greek mathematician, physicist, engineer, astronomer, and inventor from the ancient city of Syracuse in Sicily. Although few details of his life are known, he is regarded as one of the leading scientists in classical antiquity. Considered the greatest mathematician of ancient history, and one of the greatest of all time, Archimedes anticipated modern calculus and analysis by applying the concept of the infinitely small and the method of exhaustion to derive and rigorously prove a range of geometrical theorems. These include the area of a circle, the surface area and volume of a sphere, the area of an ellipse, the area under a parabola, the volume of a segment of a paraboloid of revolution, the volume of a segment of a hyperboloid of revolution, and the area of a spiral.Archimedes' other mathematical achievements include deriving an approximation of pi, defining and investigating the Archimedean spiral, and devising a system using exponentiation for expressing very large numbers. He was also one of the first to apply mathematics to physical phenomena, working on statics and hydrostatics. Archimedes' achievements in this area include a proof of the law of the lever, the widespread use of the concept of center of gravity, and the enunciation of the law of buoyancy or Archimedes' principle. He is also credited with designing innovative machines, such as his screw pump, compound pulleys, and defensive war machines to protect his native Syracuse from invasion.\n",
            "Archimedes died during the siege of Syracuse, when he was killed by a Roman soldier despite orders that he should not be harmed. Cicero describes visiting Archimedes' tomb, which was surmounted by a sphere and a cylinder that Archimedes requested be placed there to represent his mathematical discoveries.\n",
            "Unlike his inventions, Archimedes' mathematical writings were little known in antiquity. Mathematicians from Alexandria read and quoted him, but the first comprehensive compilation was not made until c. 530 AD by Isidore of Miletus in Byzantine Constantinople, while commentaries on the works of Archimedes by Eutocius in the 6th century opened them to wider readership for the first time. The relatively few copies of Archimedes' written work that survived through the Middle Ages were an influential source of ideas for scientists during the Renaissance and again in the 17th century, while the discovery in 1906 of previously lost works by Archimedes in the Archimedes Palimpsest has provided new insights into how he obtained mathematical results.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The paragraph does not mention Archimedes' last words. I need to look up \"last words\".\n",
            "Action: Lookup[last words]\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m(Result 1/1) Plutarch (45–119 AD) wrote in his Parallel Lives that Archimedes was related to King Hiero II, the ruler of Syracuse. He also provides at least two accounts on how Archimedes died after the city was taken. According to the most popular account, Archimedes was contemplating a mathematical diagram when the city was captured. A Roman soldier commanded him to come and meet Marcellus, but he declined, saying that he had to finish working on the problem. This enraged the soldier, who killed Archimedes with his sword. Another story has Archimedes carrying mathematical instruments before being killed because a soldier thought they were valuable items. Marcellus was reportedly angered by Archimedes' death, as he considered him a valuable scientific asset (he called Archimedes \"a geometrical Briareus\") and had ordered that he should not be harmed.The last words attributed to Archimedes are \"Do not disturb my circles\" (Latin, \"Noli turbare circulos meos\"; Katharevousa Greek, \"μὴ μου τοὺς κύκλους τάραττε\"), a reference to the mathematical drawing that he was supposedly studying when disturbed by the Roman soldier. There is no reliable evidence that Archimedes uttered these words and they do not appear in Plutarch's account. A similar quotation is found in the work of Valerius Maximus (fl. 30 AD), who wrote in Memorable Doings and Sayings, \"... sed protecto manibus puluere 'noli' inquit, 'obsecro, istum disturbare'\" (\"... but protecting the dust with his hands, said 'I beg of you, do not disturb this'\").\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The last words attributed to Archimedes are \"Do not disturb my circles\", so the answer is \"Do not disturb my circles\".\n",
            "Action: Finish[\"Do not disturb my circles\"]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 6064 tokens or $0.012128\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': \"What were Archimedes' last words?\",\n",
              " 'output': '\"Do not disturb my circles\"'}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# another example which involves more reasoning and the use of both the tools \n",
        "output_and_tokens(docstore_agent, \"What were Archimedes' last words?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e416a790",
      "metadata": {},
      "source": [
        "We will not print the prompt here because it is too large, but you can see it yourself if you want to (we know how to already).\n",
        "\n",
        "In short, it contains several examples of the `Question` > `Thought` > `Action` > `Observation` loop, that include the `Search` and `Lookup` tools.\n",
        "\n",
        "If you want to learn more about this approach [this](https://arxiv.org/pdf/2210.03629.pdf) is the paper for ReAct"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "663a30c8",
      "metadata": {},
      "source": [
        "### Agent type #2: Zero Shot React"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a93dc920",
      "metadata": {
        "id": "a93dc920"
      },
      "source": [
        "#### Create database"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b601f903",
      "metadata": {
        "id": "b601f903"
      },
      "source": [
        "We will use the agents to interact with a small sample database of stocks. We will not dive into the details because this is just a dummy tool we will build for illustrative purposes. Let's create it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "61b1f17c",
      "metadata": {
        "id": "61b1f17c"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import MetaData\n",
        "\n",
        "metadata_obj = MetaData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "3cc1d80e",
      "metadata": {
        "id": "3cc1d80e"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
        "\n",
        "stocks = Table(\n",
        "    \"stocks\",\n",
        "    metadata_obj,\n",
        "    Column(\"obs_id\", Integer, primary_key=True),\n",
        "    Column(\"stock_ticker\", String(4), nullable=False),\n",
        "    Column(\"price\", Float, nullable=False),\n",
        "    Column(\"date\", Date, nullable=False),    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c9a9571a",
      "metadata": {
        "id": "c9a9571a"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(\"sqlite:///:memory:\")\n",
        "metadata_obj.create_all(engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "81c3081f",
      "metadata": {
        "id": "81c3081f"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "observations = [\n",
        "    [1, 'ABC', 200, datetime(2023, 1, 1)],\n",
        "    [2, 'ABC', 208, datetime(2023, 1, 2)],\n",
        "    [3, 'ABC', 232, datetime(2023, 1, 3)],\n",
        "    [4, 'ABC', 225, datetime(2023, 1, 4)],\n",
        "    [5, 'ABC', 226, datetime(2023, 1, 5)],\n",
        "    [6, 'XYZ', 810, datetime(2023, 1, 1)],\n",
        "    [7, 'XYZ', 803, datetime(2023, 1, 2)],\n",
        "    [8, 'XYZ', 798, datetime(2023, 1, 3)],\n",
        "    [9, 'XYZ', 795, datetime(2023, 1, 4)],\n",
        "    [10, 'XYZ', 791, datetime(2023, 1, 5)],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "85fd20fa",
      "metadata": {
        "id": "85fd20fa"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import insert\n",
        "\n",
        "def insert_obs(obs):\n",
        "    stmt = insert(stocks).values(\n",
        "    obs_id=obs[0], \n",
        "    stock_ticker=obs[1], \n",
        "    price=obs[2],\n",
        "    date=obs[3]\n",
        "    )\n",
        "\n",
        "    with engine.begin() as conn:\n",
        "        conn.execute(stmt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "6766f1f7",
      "metadata": {
        "id": "6766f1f7"
      },
      "outputs": [],
      "source": [
        "for obs in observations:\n",
        "    insert_obs(obs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9721648e",
      "metadata": {
        "id": "9721648e"
      },
      "outputs": [],
      "source": [
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain.chains import SQLDatabaseChain\n",
        "\n",
        "db = SQLDatabase(engine)\n",
        "# create a database chain from the above engine, which uses the llm model to create SQL query and use it on the database\n",
        "sql_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2af8c8",
      "metadata": {
        "id": "fe2af8c8"
      },
      "source": [
        "Finally, we will create a tool with this chain. To create a custom tool we need only three inputs:\n",
        "* name: the name of the tool (sent to the llm as context)\n",
        "* func: the function that will be applied on the LLM's request\n",
        "* description: the description of the tool, what it should be used for (sent to the llm as context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "7ef519b1",
      "metadata": {
        "id": "7ef519b1"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "# the tool is a function that the agent can use when necessary\n",
        "sql_tool = Tool(\n",
        "    name='Stock DB',\n",
        "    # chain that need to be used\n",
        "    func=sql_chain.run,\n",
        "    # tells the agent when to use the tool \n",
        "    description=\"Useful for when you need to answer questions about stocks \" \\\n",
        "                \"and their prices.\"\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13951c49",
      "metadata": {
        "id": "13951c49"
      },
      "source": [
        "We will be using only a few tools but you can combine the ones you prefer. Remember that tools are only utility chains under the hood which are chains that serve one specific purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabcff15",
      "metadata": {
        "id": "aabcff15"
      },
      "source": [
        "We first need to initialize the tools we'll be using in this example. Here we will want our agent to do math so we will use 'llm-math', the tool we have for solving math problems. This is one of the several tools we can load with the `load_tools` utility - you can check out more by checking out the [docs](https://langchain.readthedocs.io/en/latest/modules/agents/tools.html?highlight=tools#tools)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "0c6bd290",
      "metadata": {
        "id": "0c6bd290"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "# load one tool\n",
        "tools = load_tools(\n",
        "    [\"llm-math\"], \n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf01b924",
      "metadata": {
        "id": "bf01b924"
      },
      "source": [
        "To be able to search across our stock prices, we will also use the custom tool we built beforehand with the sql data ('Stock DB'). We will append this tool to our list of tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "e9d016d7",
      "metadata": {
        "id": "e9d016d7"
      },
      "outputs": [],
      "source": [
        "# append the sql tool\n",
        "tools.append(sql_tool)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc9bf6b5",
      "metadata": {
        "id": "bc9bf6b5"
      },
      "source": [
        "As the name suggests, we will use this agent to perform 'zero shot' tasks on the input. That means that we will not have several, interdependent interactions but only one. In other words, this agent will have no memory."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6e51d51",
      "metadata": {
        "id": "a6e51d51"
      },
      "source": [
        "Now we are ready to initialize the agent! We will use `verbose` in `True` so we can see what is our agent's 'thinking' process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca2d95ce",
      "metadata": {
        "id": "ca2d95ce"
      },
      "source": [
        "**Important Note:** *When interacting with agents it is really important to set the `max_iterations` parameters because agents can get stuck in infinite loops that consume plenty of tokens. The default value is 15 to allow for many tools and complex reasoning but for most applications you should keep it much lower.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "5e4eb28c",
      "metadata": {
        "id": "5e4eb28c"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "# initialise the zero_shot_agent\n",
        "zero_shot_agent = initialize_agent(\n",
        "    agent=\"zero-shot-react-description\", \n",
        "    tools=tools, \n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    # how many iteration should the agent go through to find the answer\n",
        "    max_iterations=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28c239c0",
      "metadata": {
        "id": "28c239c0"
      },
      "source": [
        "Let's see our newly created agent in action! We will ask it a question that involves a math operation over the stock prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "9c775bc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c775bc6",
        "outputId": "979f31fc-c606-473d-deb3-3b1dc0222a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to compare the stock prices for the two dates\n",
            "Action: Stock DB\n",
            "Action Input: stock prices for 'ABC' and 'XYZ' on January 3rd and January 4th\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "stock prices for 'ABC' and 'XYZ' on January 3rd and January 4th \n",
            "SQLQuery:\u001b[32;1m\u001b[1;3m SELECT stock_ticker, price, date FROM stocks WHERE (stock_ticker = 'ABC' OR stock_ticker = 'XYZ') AND date IN ('2023-01-03', '2023-01-04')\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[('ABC', 232.0, '2023-01-03'), ('ABC', 225.0, '2023-01-04'), ('XYZ', 798.0, '2023-01-03'), ('XYZ', 795.0, '2023-01-04')]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3m The stock prices for 'ABC' and 'XYZ' on January 3rd and January 4th were 232.0, 225.0, 798.0 and 795.0 respectively.\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m The stock prices for 'ABC' and 'XYZ' on January 3rd and January 4th were 232.0, 225.0, 798.0 and 795.0 respectively.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the multiplication of the ratio\n",
            "Action: Calculator\n",
            "Action Input: 232.0/225.0 * 798.0/795.0\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 1.0350020964360587\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The multiplication of the ratio between stock prices for 'ABC' and 'XYZ' on January 3rd and January 4th is 1.0350020964360587.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 2082 tokens or $0.004164\n"
          ]
        }
      ],
      "source": [
        "result = output_and_tokens(\n",
        "    zero_shot_agent, \n",
        "    \"What is the multiplication of the ratio between stock prices for 'ABC' and 'XYZ' in January 3rd and the ratio between the same stock prices in January the 4th?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b23c42",
      "metadata": {
        "id": "b8b23c42"
      },
      "source": [
        "As always, let's see what the prompt is here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "3e50e81b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e50e81b",
        "outputId": "c1fb3eb0-01b5-46e1-f17b-d1df2bff2df3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Calculator: Useful for when you need to answer questions about math.\n",
            "Stock DB: Useful for when you need to answer questions about stocks and their prices.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Calculator, Stock DB]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ],
      "source": [
        "print(zero_shot_agent.agent.llm_chain.prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b2b47ed",
      "metadata": {
        "id": "5b2b47ed"
      },
      "source": [
        "The question we must ask ourselves here is: how are agents different than chains?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f73aaf07",
      "metadata": {
        "id": "f73aaf07"
      },
      "source": [
        "If we look at the agent's logic and the prompt we have just printed we will see some clear differences. First, we have the tools which are included in the prompt. Second we have a thought process which was before was immediate in chains but now involves a 'thought', 'action', 'action input', 'observation' sequence. What is this all about?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a698f78",
      "metadata": {
        "id": "3a698f78"
      },
      "source": [
        "Suffice it to say for now that **the LLM now has the ability to 'reason' on how to best use tools** to solve our query and can combine them in intelligent ways with just a brief description of each of them. If you want to learn more about this paradigm (MRKL) in detail, please refer to [this](https://arxiv.org/pdf/2205.00445.pdf) paper. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff9e65d",
      "metadata": {
        "id": "aff9e65d"
      },
      "source": [
        "Finally, let's pay attention to the 'agent_scratchpad'. What is that? Well, that is where we will be appending every thought or action that the agent has already performed. In this way, at each point in time, the agent will know what it has found out and will be able to continue its thought process. In other words, after using a tool it adds its thoughts and observations to the scratchpad and picks up from there."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "vercel_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
